{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d2596e48ed74422787c6757145f6987e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_01584b70a52f49a1af5c4b5938ca4866",
              "IPY_MODEL_5acd0831d01043038487bae42b3c914e",
              "IPY_MODEL_a16e2733c699454d967fd3b469133951"
            ],
            "layout": "IPY_MODEL_28b21825068e4371ab8f9356e4431afe"
          }
        },
        "01584b70a52f49a1af5c4b5938ca4866": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_340503d2ea1b406a9804eda9756d282f",
            "placeholder": "​",
            "style": "IPY_MODEL_44a5b950e2e246209d9cf117e1a1962a",
            "value": "NER chunks: 100%"
          }
        },
        "5acd0831d01043038487bae42b3c914e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1aa8667331b24baca443fb6a2a6c8f13",
            "max": 393,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ac03599b9ec3488787cf8e010f4011ce",
            "value": 393
          }
        },
        "a16e2733c699454d967fd3b469133951": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5007d2453cc464590dd21c169852497",
            "placeholder": "​",
            "style": "IPY_MODEL_1c053864efeb4280b251113107a6975c",
            "value": " 393/393 [00:17&lt;00:00, 18.87it/s]"
          }
        },
        "28b21825068e4371ab8f9356e4431afe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "340503d2ea1b406a9804eda9756d282f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44a5b950e2e246209d9cf117e1a1962a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1aa8667331b24baca443fb6a2a6c8f13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac03599b9ec3488787cf8e010f4011ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c5007d2453cc464590dd21c169852497": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c053864efeb4280b251113107a6975c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#@title Téléchargement des oeuvres de Flaubert\n",
        "\n",
        "import urllib.request\n",
        "import os\n",
        "\n",
        "# Charger les oeuvres de Flaubert\n",
        "flaubert = {\n",
        "    \"Madame_Bovary\": \"https://www.gutenberg.org/cache/epub/14155/pg14155.txt\",\n",
        "    \"L_Education_sentimentale\": \"https://www.gutenberg.org/cache/epub/49773/pg49773.txt\",\n",
        "    \"Bouvard_et_Pecuchet\": \"https://www.gutenberg.org/cache/epub/14157/pg14157.txt\",\n",
        "    \"Salammbô\": \"https://www.gutenberg.org/cache/epub/48881/pg48881.txt\",\n",
        "    \"Trois_Contes\": \"https://www.gutenberg.org/cache/epub/12065/pg12065.txt\",\n",
        "    \"Un_Coeur_simple\": \"https://www.gutenberg.org/cache/epub/26812/pg26812.txt\",\n",
        "    \"Dictionnaire_des_idees_recues\": \"https://www.gutenberg.org/cache/epub/14156/pg14156.txt\"\n",
        "}\n",
        "\n",
        "os.makedirs('/content/romans_Flaubert', exist_ok=True)\n",
        "\n",
        "# Boucle sur chaque ouvrage\n",
        "for titre, url in flaubert.items():\n",
        "    # Construire le chemin complet : dossier/titre_du_livre.txt\n",
        "    chemin_fichier = os.path.join('/content/romans_Flaubert', f\"{titre}.txt\")\n",
        "\n",
        "    print(f\"Téléchargement de '{titre}'...\")\n",
        "\n",
        "    urllib.request.urlretrieve(url, chemin_fichier)\n",
        "\n",
        "print(f\"\\nTous les ouvrages ont été téléchargés.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QhX0srmeVuSj",
        "outputId": "b4b962fa-18c4-43c5-cb72-7c6e8cd86fa8",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Téléchargement de 'Madame_Bovary'...\n",
            "Téléchargement de 'L_Education_sentimentale'...\n",
            "Téléchargement de 'Bouvard_et_Pecuchet'...\n",
            "Téléchargement de 'Salammbô'...\n",
            "Téléchargement de 'Trois_Contes'...\n",
            "Téléchargement de 'Un_Coeur_simple'...\n",
            "Téléchargement de 'Dictionnaire_des_idees_recues'...\n",
            "\n",
            "Tous les ouvrages ont été téléchargés.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Méthode de découpage basée sur les normes des fichiers issus du Projet Gutenberg\n",
        "\n",
        "from pathlib import Path\n",
        "import re, os, tempfile, unicodedata\n",
        "\n",
        "START_PATTERNS = [\n",
        "    re.compile(r'(?i)(?:\\*{1,}\\s*)?(start|begin)(?:\\s+of)?(?:\\s+the)?\\s+project\\s+gutenberg'),\n",
        "    re.compile(r'(?i)start\\s+of\\s+this\\s+project\\s+gutenberg'),\n",
        "    re.compile(r'(?i)project\\s+gutenberg.*start'),\n",
        "]\n",
        "END_PATTERNS = [\n",
        "    re.compile(r'(?i)(?:\\*{1,}\\s*)?(end|finish|finis?h|stop)(?:\\s+of)?(?:\\s+the)?\\s+project\\s+gutenberg'),\n",
        "    re.compile(r'(?i)end\\s+of\\s+this\\s+project\\s+gutenberg'),\n",
        "    re.compile(r'(?i)project\\s+gutenberg.*end'),\n",
        "]\n",
        "\n",
        "def _norm(s: str) -> str:\n",
        "    # normalize and unify NBSP etc.\n",
        "    return unicodedata.normalize('NFKC', s).replace('\\u00A0', ' ')\n",
        "\n",
        "def _find_marker(lines, patterns, reverse=False):\n",
        "    rng = range(len(lines)-1, -1, -1) if reverse else range(len(lines))\n",
        "    for i in rng:\n",
        "        L = _norm(lines[i]).strip()\n",
        "        for p in patterns:\n",
        "            if p.search(L):\n",
        "                return i\n",
        "    return None\n",
        "\n",
        "def gutenberg_strip_text(text: str):\n",
        "    text = _norm(text).replace('\\r\\n', '\\n')\n",
        "    lines = text.splitlines(keepends=True)\n",
        "    s_idx = _find_marker(lines, START_PATTERNS, reverse=False)\n",
        "    e_idx = _find_marker(lines, END_PATTERNS, reverse=True)\n",
        "    # if neither marker found, return original and markers=None\n",
        "    if s_idx is None and e_idx is None:\n",
        "        return text, None, None\n",
        "    # compute slice: default to start 0 / end len if marker absent\n",
        "    start = (s_idx + 1) if s_idx is not None else 0\n",
        "    end = e_idx if e_idx is not None else len(lines)\n",
        "    # safety: if start >= end, do not strip (return original)\n",
        "    if start >= end:\n",
        "        return text, s_idx, e_idx\n",
        "    body = lines[start:end]\n",
        "    # strip leading/trailing blank lines\n",
        "    while body and body[0].strip() == '':\n",
        "        body.pop(0)\n",
        "    while body and body[-1].strip() == '':\n",
        "        body.pop()\n",
        "    return ''.join(body), s_idx, e_idx\n",
        "\n",
        "# tokenizer: prefer tiktoken if available, fallback to simple word count\n",
        "try:\n",
        "    import tiktoken\n",
        "    enc = tiktoken.get_encoding(\"cl100k_base\")\n",
        "    def token_count(s: str) -> int:\n",
        "        return len(enc.encode(s))\n",
        "except Exception:\n",
        "    def token_count(s: str) -> int:\n",
        "        return 0 if not s.strip() else len(re.findall(r'\\S+', s))\n",
        "\n",
        "# Loop\n",
        "FOLDER = Path(\"/content/romans_Flaubert\")\n",
        "if not FOLDER.exists():\n",
        "    raise SystemExit(f\"Folder not found: {FOLDER}\")\n",
        "\n",
        "total_deleted = 0\n",
        "files = sorted(FOLDER.glob(\"*.txt\"))\n",
        "if not files:\n",
        "    print(\"No .txt files found in\", FOLDER)\n",
        "for path in files:\n",
        "    txt = path.read_text(encoding=\"utf-8\", errors=\"replace\")\n",
        "    stripped, s_idx, e_idx = gutenberg_strip_text(txt)\n",
        "    if s_idx is None and e_idx is None:\n",
        "        print(f\"{path.name}: left unchanged\")\n",
        "        continue\n",
        "    orig_tokens = token_count(txt)\n",
        "    new_tokens = token_count(stripped)\n",
        "    deleted = max(0, orig_tokens - new_tokens)\n",
        "    # atomic overwrite in same dir\n",
        "    with tempfile.NamedTemporaryFile(\"w\", delete=False, encoding=\"utf-8\", dir=path.parent) as tmp:\n",
        "        tmp.write(stripped)\n",
        "    os.replace(tmp.name, path)\n",
        "    total_deleted += deleted\n",
        "    print(f\"{path.name}: start_line={s_idx} end_line={e_idx} tokens_deleted={deleted} (orig {orig_tokens} → {new_tokens})\")\n",
        "\n",
        "print(f\"\\nProcessed {len(files)} files. Total tokens deleted: {total_deleted}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1eHIAd_KWjjE",
        "outputId": "c6cc4673-f611-4e4e-dd82-167273cf2859",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bouvard_et_Pecuchet.txt: start_line=22 end_line=12968 tokens_deleted=716 (orig 176891 → 176175)\n",
            "Dictionnaire_des_idees_recues.txt: start_line=22 end_line=2931 tokens_deleted=721 (orig 28750 → 28029)\n",
            "L_Education_sentimentale.txt: start_line=25 end_line=9690 tokens_deleted=812 (orig 135147 → 134335)\n",
            "Madame_Bovary.txt: start_line=22 end_line=14832 tokens_deleted=705 (orig 219615 → 218910)\n",
            "Salammbô.txt: start_line=25 end_line=13529 tokens_deleted=791 (orig 220295 → 219504)\n",
            "Trois_Contes.txt: start_line=25 end_line=4158 tokens_deleted=747 (orig 63576 → 62829)\n",
            "Un_Coeur_simple.txt: start_line=22 end_line=1968 tokens_deleted=691 (orig 25973 → 25282)\n",
            "\n",
            "Processed 7 files. Total tokens deleted: 5183\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title camembert-ner sur Madame Bovary\n",
        "\n",
        "!pip install -q transformers[torch] datasets sentencepiece nltk\n",
        "!pip install -q --upgrade accelerate\n",
        "\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForTokenClassification\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import json, csv, os, math\n",
        "from pathlib import Path\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "MODEL_NAME = \"Jean-Baptiste/camembert-ner\"   # recommended for French (change if you prefer)\n",
        "TXT_PATH = \"/content/romans_Flaubert/Madame_Bovary.txt\"      # path to your raw txt file\n",
        "OUTPUT_DIR = \"/content/ner_bovary\"\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "DEVICE = 0   # Colab GPU device index (0 for the assigned GPU)\n",
        "\n",
        "# 4) Load model/tokenizer and HF NER pipeline (on GPU)\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
        "model = AutoModelForTokenClassification.from_pretrained(MODEL_NAME)\n",
        "# Create pipeline - use aggregation if available (returns grouped entities)\n",
        "try:\n",
        "    nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer,\n",
        "                   device=DEVICE, aggregation_strategy=\"simple\")\n",
        "except TypeError:\n",
        "    # fallback for older transformers versions\n",
        "    nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer,\n",
        "                   device=DEVICE, grouped_entities=True)\n",
        "\n",
        "# 5) Read the book\n",
        "with open(TXT_PATH, \"r\", encoding=\"utf-8\") as f:\n",
        "    text = f.read()\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')  # <-- add this line\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "# Then re-run your sentence splitting\n",
        "sentences = sent_tokenize(text, language='french')\n",
        "print(f\"Total sentences: {len(sentences)}\")\n",
        "\n",
        "# 7) Build chunks (accumulate sentences until token length near model max)\n",
        "max_tokens = tokenizer.model_max_length\n",
        "# keep a margin to avoid truncation:\n",
        "MARGIN = 32\n",
        "chunks = []\n",
        "chunk_start_indices = []  # start char index of each chunk in original text\n",
        "\n",
        "cursor = 0  # position in original text for searching next sentence\n",
        "current_chunk = \"\"\n",
        "current_chunk_start = None\n",
        "\n",
        "for sent in sentences:\n",
        "    # find next occurrence of the sentence starting from cursor to compute true char offsets\n",
        "    found = text.find(sent, cursor)\n",
        "    if found == -1:\n",
        "        # fallback: use cursor as start (rare)\n",
        "        found = cursor\n",
        "    cursor = found + len(sent)\n",
        "\n",
        "    if current_chunk == \"\":\n",
        "        current_chunk_start = found\n",
        "\n",
        "    # estimate token length by tokenizer\n",
        "    tmp = current_chunk + \" \" + sent if current_chunk else sent\n",
        "    token_len = len(tokenizer(tmp, return_tensors=\"pt\")[\"input_ids\"][0])\n",
        "    if token_len + MARGIN < max_tokens:\n",
        "        current_chunk = tmp\n",
        "    else:\n",
        "        # flush existing chunk\n",
        "        chunks.append(current_chunk)\n",
        "        chunk_start_indices.append(current_chunk_start)\n",
        "        # start new chunk with current sentence\n",
        "        current_chunk = sent\n",
        "        current_chunk_start = found\n",
        "\n",
        "# flush last\n",
        "if current_chunk:\n",
        "    chunks.append(current_chunk)\n",
        "    chunk_start_indices.append(current_chunk_start)\n",
        "\n",
        "print(f\"Total chunks built: {len(chunks)} (model max tokens: {max_tokens})\")\n",
        "\n",
        "# 8) Run NER over chunks (batched) and collect absolute offsets\n",
        "all_entities = []\n",
        "for chunk_text, chunk_start in tqdm(list(zip(chunks, chunk_start_indices)), desc=\"NER chunks\"):\n",
        "    results = nlp(chunk_text)\n",
        "    # results: list of dicts, each with keys like 'entity_group' or 'entity' (depends on HF version),\n",
        "    # and 'start','end','score','word'\n",
        "    for ent in results:\n",
        "        # handle aggregated vs non-aggregated output differences\n",
        "        if \"entity_group\" in ent:\n",
        "            ent_type = ent[\"entity_group\"]\n",
        "        else:\n",
        "            # older output may use 'entity' like 'B-PER' -> normalize\n",
        "            ent_type = ent.get(\"entity\", ent.get(\"label\"))\n",
        "        start = ent.get(\"start\")\n",
        "        end = ent.get(\"end\")\n",
        "        if start is None or end is None:\n",
        "            # if pipeline didn't return character offsets, skip (rare with fast tokenizers & aggregation)\n",
        "            continue\n",
        "        abs_start = chunk_start + start\n",
        "        abs_end = chunk_start + end\n",
        "        snippet = text[max(0, abs_start-40):min(len(text), abs_end+40)]\n",
        "        all_entities.append({\n",
        "            \"text\": ent.get(\"word\", text[abs_start:abs_end]),\n",
        "            \"type\": ent_type,\n",
        "            \"start\": abs_start,\n",
        "            \"end\": abs_end,\n",
        "            \"score\": float(ent.get(\"score\", 0.0)),\n",
        "            \"context\": snippet\n",
        "        })\n",
        "\n",
        "print(f\"Raw extracted entities: {len(all_entities)}\")\n",
        "\n",
        "# 9) Simple post-processing: deduplicate & merge identical spans\n",
        "# Convert to a dict keyed by (start,end,type,text) to deduplicate\n",
        "unique = {}\n",
        "for e in all_entities:\n",
        "    key = (e[\"start\"], e[\"end\"], e[\"type\"], e[\"text\"])\n",
        "    # keep highest-score instance\n",
        "    if key not in unique or unique[key][\"score\"] < e[\"score\"]:\n",
        "        unique[key] = e\n",
        "\n",
        "entities_dedup = list(unique.values())\n",
        "entities_dedup = sorted(entities_dedup, key=lambda x: (x[\"start\"], -x[\"score\"]))\n",
        "\n",
        "print(f\"Entities after deduplication: {len(entities_dedup)}\")\n",
        "\n",
        "# 10) Save JSON and CSV\n",
        "json_path = os.path.join(OUTPUT_DIR, \"madame_bovary_ner.json\")\n",
        "csv_path = os.path.join(OUTPUT_DIR, \"madame_bovary_ner.csv\")\n",
        "with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(entities_dedup, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "with open(csv_path, \"w\", encoding=\"utf-8\", newline='') as f:\n",
        "    writer = csv.DictWriter(f, fieldnames=[\"text\",\"type\",\"start\",\"end\",\"score\",\"context\"])\n",
        "    writer.writeheader()\n",
        "    for e in entities_dedup:\n",
        "        writer.writerow(e)\n",
        "\n",
        "print(\"Saved:\", json_path, csv_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301,
          "referenced_widgets": [
            "d2596e48ed74422787c6757145f6987e",
            "01584b70a52f49a1af5c4b5938ca4866",
            "5acd0831d01043038487bae42b3c914e",
            "a16e2733c699454d967fd3b469133951",
            "28b21825068e4371ab8f9356e4431afe",
            "340503d2ea1b406a9804eda9756d282f",
            "44a5b950e2e246209d9cf117e1a1962a",
            "1aa8667331b24baca443fb6a2a6c8f13",
            "ac03599b9ec3488787cf8e010f4011ce",
            "c5007d2453cc464590dd21c169852497",
            "1c053864efeb4280b251113107a6975c"
          ]
        },
        "id": "9j5JisupVu7Y",
        "outputId": "730fbe59-e31c-468f-e30a-2dca717dc0ee",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "Device set to use cuda:0\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (515 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total sentences: 6906\n",
            "Total chunks built: 393 (model max tokens: 512)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "NER chunks:   0%|          | 0/393 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d2596e48ed74422787c6757145f6987e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw extracted entities: 3251\n",
            "Entities after deduplication: 3251\n",
            "Saved: /content/ner_bovary/madame_bovary_ner.json /content/ner_bovary/madame_bovary_ner.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === PERSON EXTRACTION TOOL ===\n",
        "\n",
        "import os\n",
        "import json\n",
        "import csv\n",
        "from collections import defaultdict, Counter\n",
        "import pandas as pd\n",
        "import re\n",
        "from difflib import SequenceMatcher, get_close_matches\n",
        "\n",
        "# Optional: fuzzy merging\n",
        "# !pip install -q rapidfuzz\n",
        "# from rapidfuzz import process, fuzz\n",
        "\n",
        "# ---------- USER SETTINGS ----------\n",
        "INPUT_PATH = \"/content/ner_results/madame_bovary_ner.json\"  # change to your CSV or JSON\n",
        "OUTPUT_DIR = \"/content/persons_output\"\n",
        "FUZZY_MERGE = True     # try to merge similar names (True = attempt fuzzy merging)\n",
        "FUZZY_SIMILARITY_THRESHOLD = 0.87  # 0..1 for difflib; if using rapidfuzz this would be 87\n",
        "# -----------------------------------\n",
        "\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# ---------- Helpers ----------\n",
        "def load_input(path):\n",
        "    path = str(path)\n",
        "    if path.lower().endswith(\".json\"):\n",
        "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "            data = json.load(f)\n",
        "        # Expect either a list of entity dicts or nested structure; try to flatten common shapes\n",
        "        if isinstance(data, dict) and \"entities\" in data and isinstance(data[\"entities\"], list):\n",
        "            return data[\"entities\"]\n",
        "        if isinstance(data, list):\n",
        "            return data\n",
        "        raise ValueError(\"JSON structure not recognized: expected list of entity dicts or {'entities': [...]}\")\n",
        "\n",
        "    elif path.lower().endswith(\".csv\"):\n",
        "        df = pd.read_csv(path, dtype=str).fillna(\"\")\n",
        "        # convert to list of dicts\n",
        "        return df.to_dict(orient=\"records\")\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported input format: must be .json or .csv\")\n",
        "\n",
        "def is_person_label(label_value):\n",
        "    \"\"\"Return True if the label value indicates a person name.\"\"\"\n",
        "    if not label_value:\n",
        "        return False\n",
        "    v = str(label_value).upper()\n",
        "    # Common patterns: \"PER\", \"PERSON\", \"NER\" (user said 'NER'), B-PER/I-PER, \"PERSONNE\" (French)\n",
        "    candidates = [\"PER\", \"PERSON\", \"PERSONNE\", \"NER\", \"PERS\"]\n",
        "    # direct contains\n",
        "    for c in candidates:\n",
        "        if c in v:\n",
        "            return True\n",
        "    # case: \"B-PER\", \"I-PER\", \"B-PERSON\"\n",
        "    if re.search(r\"\\bB[-_]?PER\\b|\\bI[-_]?PER\\b\", v):\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "def normalize_name(name):\n",
        "    \"\"\"Lower-level normalization: strip whitespace, unify spaces, strip punctuation edges.\"\"\"\n",
        "    if name is None:\n",
        "        return \"\"\n",
        "    s = str(name)\n",
        "    s = s.strip()\n",
        "    # Replace weird tokenization artifacts (e.g., '##' subword markers or '▁' from SentencePiece)\n",
        "    s = s.replace(\"##\", \"\").replace(\"▁\", \" \")\n",
        "    # collapse whitespace\n",
        "    s = re.sub(r\"\\s+\", \" \", s)\n",
        "    # remove surrounding punctuation like quotes or parentheses\n",
        "    s = s.strip(\" \\\"'«»(),;:.\")\n",
        "    return s\n",
        "\n",
        "def similar(a, b):\n",
        "    \"\"\"Similarity metric 0..1 using SequenceMatcher\"\"\"\n",
        "    if not a or not b:\n",
        "        return 0.0\n",
        "    return SequenceMatcher(None, a, b).ratio()\n",
        "\n",
        "# ---------- Load ----------\n",
        "records = load_input(INPUT_PATH)\n",
        "print(f\"Loaded {len(records)} records from {INPUT_PATH}\")\n",
        "\n",
        "# ---------- Extract person-name occurrences ----------\n",
        "occurrences = []  # list of dicts {name, label_key, score, start, end, raw_text}\n",
        "for rec in records:\n",
        "    # possible name fields\n",
        "    name = None\n",
        "    # Common keys from HF pipeline: 'word', 'entity', 'label', 'entity_group', 'type', 'text'\n",
        "    for k in (\"word\", \"text\", \"entity\", \"label\", \"entity_group\", \"type\"):\n",
        "        if k in rec and rec[k] not in (None, \"\"):\n",
        "            # some pipelines produce multi-token grouped entity as 'word', prefer that\n",
        "            name = rec[k]\n",
        "            label_key = rec.get(\"entity_group\") or rec.get(\"label\") or rec.get(\"type\") or rec.get(\"entity\") or \"\"\n",
        "            break\n",
        "\n",
        "    if name is None:\n",
        "        # try to reconstruct from character offsets if present\n",
        "        if \"start\" in rec and \"end\" in rec and \"context\" in rec:\n",
        "            # as fallback, try to extract substring from context if rec doesn't include exact text\n",
        "            name = rec.get(\"word\") or rec.get(\"text\") or \"\"\n",
        "        else:\n",
        "            continue\n",
        "\n",
        "    name_norm = normalize_name(name)\n",
        "    # find label value if present under various keys\n",
        "    label_value = rec.get(\"entity_group\") or rec.get(\"type\") or rec.get(\"label\") or rec.get(\"entity\") or \"\"\n",
        "    if is_person_label(label_value):\n",
        "        # parse score if present\n",
        "        try:\n",
        "            score = float(rec.get(\"score\", rec.get(\"probability\", 0.0) or 0.0))\n",
        "        except Exception:\n",
        "            score = 0.0\n",
        "        occurrence = {\n",
        "            \"raw\": name,\n",
        "            \"name\": name_norm,\n",
        "            \"label\": label_value,\n",
        "            \"score\": score,\n",
        "            \"start\": rec.get(\"start\"),\n",
        "            \"end\": rec.get(\"end\"),\n",
        "            \"context\": rec.get(\"context\", \"\")\n",
        "        }\n",
        "        if occurrence[\"name\"]:  # ignore empty\n",
        "            occurrences.append(occurrence)\n",
        "\n",
        "print(f\"Detected {len(occurrences)} person occurrences (pre-dedup).\")\n",
        "\n",
        "# ---------- Aggregate exact names ----------\n",
        "counts = defaultdict(int)\n",
        "scores_sum = defaultdict(float)\n",
        "occ_list = defaultdict(list)\n",
        "for occ in occurrences:\n",
        "    k = occ[\"name\"]\n",
        "    counts[k] += 1\n",
        "    scores_sum[k] += occ[\"score\"]\n",
        "    occ_list[k].append(occ)\n",
        "\n",
        "# Build initial unique names list\n",
        "unique_names = sorted(counts.keys(), key=lambda x: (-counts[x], x))\n",
        "print(f\"{len(unique_names)} unique person strings found before fuzzy merging.\")\n",
        "\n",
        "# ---------- Optional fuzzy merging ----------\n",
        "if FUZZY_MERGE and len(unique_names) > 0:\n",
        "    merged_map = {}   # maps original name -> canonical name\n",
        "    canonicals = []   # list of canonical names\n",
        "    for name in unique_names:\n",
        "        # try to find an existing canonical that is similar enough\n",
        "        found = None\n",
        "        for c in canonicals:\n",
        "            if similar(name.lower(), c.lower()) >= FUZZY_SIMILARITY_THRESHOLD:\n",
        "                found = c\n",
        "                break\n",
        "        if found is None:\n",
        "            # no close match: create new canonical\n",
        "            canonicals.append(name)\n",
        "            merged_map[name] = name\n",
        "        else:\n",
        "            merged_map[name] = found\n",
        "\n",
        "    # If you prefer rapidfuzz, you could do a higher-quality matching:\n",
        "    # use rapidfuzz.process.extractOne(name, canonicals, scorer=fuzz.WRatio)\n",
        "    # but avoid requiring extra install by default.\n",
        "\n",
        "    # Build merged aggregates\n",
        "    merged_counts = defaultdict(int)\n",
        "    merged_scores_sum = defaultdict(float)\n",
        "    merged_occ_list = defaultdict(list)\n",
        "    for orig_name, cnt in counts.items():\n",
        "        canon = merged_map.get(orig_name, orig_name)\n",
        "        merged_counts[canon] += cnt\n",
        "        merged_scores_sum[canon] += scores_sum[orig_name]\n",
        "        merged_occ_list[canon].extend(occ_list[orig_name])\n",
        "\n",
        "    # overwrite\n",
        "    counts = merged_counts\n",
        "    scores_sum = merged_scores_sum\n",
        "    occ_list = merged_occ_list\n",
        "\n",
        "print(f\"{len(counts)} names after merging.\")\n",
        "\n",
        "# ---------- Prepare outputs ----------\n",
        "rows = []\n",
        "for name, cnt in sorted(counts.items(), key=lambda x: (-x[1], x[0])):\n",
        "    mean_score = scores_sum[name] / cnt if cnt else 0.0\n",
        "    example_context = occ_list[name][0][\"context\"] if occ_list[name] else \"\"\n",
        "    rows.append({\n",
        "        \"name\": name,\n",
        "        \"count\": cnt,\n",
        "        \"mean_score\": mean_score,\n",
        "        \"example_context\": example_context,\n",
        "        \"occurrences\": occ_list[name]\n",
        "    })\n",
        "\n",
        "# Write persons_unique.txt\n",
        "txt_path = os.path.join(OUTPUT_DIR, \"persons_unique.txt\")\n",
        "with open(txt_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    for r in rows:\n",
        "        f.write(f\"{r['name']}\\n\")\n",
        "\n",
        "# Write persons_counts.csv\n",
        "csv_path = os.path.join(OUTPUT_DIR, \"persons_counts.csv\")\n",
        "with open(csv_path, \"w\", encoding=\"utf-8\", newline='') as f:\n",
        "    writer = csv.DictWriter(f, fieldnames=[\"name\",\"count\",\"mean_score\",\"example_context\"])\n",
        "    writer.writeheader()\n",
        "    for r in rows:\n",
        "        writer.writerow({\n",
        "            \"name\": r[\"name\"],\n",
        "            \"count\": r[\"count\"],\n",
        "            \"mean_score\": r[\"mean_score\"],\n",
        "            \"example_context\": r[\"example_context\"]\n",
        "        })\n",
        "\n",
        "# Write persons_normalized.json (full details)\n",
        "json_path = os.path.join(OUTPUT_DIR, \"persons_normalized.json\")\n",
        "with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(rows, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(\"Wrote outputs to:\", OUTPUT_DIR)\n",
        "print(\"Top 20 persons (by frequency):\")\n",
        "for r in rows[:20]:\n",
        "    print(f\"  {r['name']} — {r['count']} occurrences, mean score {r['mean_score']:.3f}\")\n",
        "\n",
        "try:\n",
        "    import pandas as pd\n",
        "    display_df = pd.DataFrame([{\"name\": r[\"name\"], \"count\": r[\"count\"], \"mean_score\": r[\"mean_score\"]} for r in rows])\n",
        "    from IPython.display import display\n",
        "    display(display_df.head(30))\n",
        "except Exception:\n",
        "    pass\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HY-89z-UXWy4",
        "outputId": "50b33ab9-22fb-49dc-e2c5-541fa1a12ee7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 3279 records from /content/ner_results/madame_bovary_ner.json\n",
            "Detected 1929 person occurrences (pre-dedup).\n",
            "366 unique person strings found before fuzzy merging.\n",
            "338 names after merging.\n",
            "Wrote outputs to: /content/persons_output\n",
            "Top 20 persons (by frequency):\n",
            "  Charles — 300 occurrences, mean score 0.833\n",
            "  Emma — 199 occurrences, mean score 0.708\n",
            "  Léon — 118 occurrences, mean score 0.797\n",
            "  Homais — 104 occurrences, mean score 0.988\n",
            "  Rodolphe — 96 occurrences, mean score 0.791\n",
            "  Madame — 48 occurrences, mean score 0.813\n",
            "  Lheureux — 42 occurrences, mean score 0.991\n",
            "  M. Homais — 40 occurrences, mean score 0.923\n",
            "  Justin — 36 occurrences, mean score 0.911\n",
            "  Binet — 28 occurrences, mean score 0.995\n",
            "  Félicité — 26 occurrences, mean score 0.775\n",
            "  Hippolyte — 24 occurrences, mean score 0.858\n",
            "  M. Lheureux — 24 occurrences, mean score 0.955\n",
            "  madame Homais — 22 occurrences, mean score 0.891\n",
            "  Monsieur — 21 occurrences, mean score 0.830\n",
            "  Rouault — 16 occurrences, mean score 0.969\n",
            "  Berthe — 15 occurrences, mean score 0.778\n",
            "  Hivert — 15 occurrences, mean score 0.987\n",
            "  madame Lefrançois — 15 occurrences, mean score 0.938\n",
            "  père Rouault — 15 occurrences, mean score 0.890\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                 name  count  mean_score\n",
              "0             Charles    300    0.833176\n",
              "1                Emma    199    0.707597\n",
              "2                Léon    118    0.796928\n",
              "3              Homais    104    0.988069\n",
              "4            Rodolphe     96    0.790957\n",
              "5              Madame     48    0.813232\n",
              "6            Lheureux     42    0.991086\n",
              "7           M. Homais     40    0.922977\n",
              "8              Justin     36    0.910620\n",
              "9               Binet     28    0.995274\n",
              "10           Félicité     26    0.775054\n",
              "11          Hippolyte     24    0.857947\n",
              "12        M. Lheureux     24    0.955307\n",
              "13      madame Homais     22    0.890803\n",
              "14           Monsieur     21    0.830093\n",
              "15            Rouault     16    0.969070\n",
              "16             Berthe     15    0.778214\n",
              "17             Hivert     15    0.986507\n",
              "18  madame Lefrançois     15    0.938374\n",
              "19       père Rouault     15    0.890304\n",
              "20            Canivet     14    0.983610\n",
              "21         Lefrançois     14    0.986711\n",
              "22            Tuvache     13    0.974829\n",
              "23         Bournisien     11    0.973066\n",
              "24       Lestiboudois     11    0.887517\n",
              "25              Rodol     11    0.551710\n",
              "26            Vinçart     11    0.981382\n",
              "27                 or     11    0.762558\n",
              "28         Conseiller     10    0.792756\n",
              "29                  L     10    0.847892"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-df5461ee-4420-4088-8653-a83a9bc6cd8a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>count</th>\n",
              "      <th>mean_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Charles</td>\n",
              "      <td>300</td>\n",
              "      <td>0.833176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Emma</td>\n",
              "      <td>199</td>\n",
              "      <td>0.707597</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Léon</td>\n",
              "      <td>118</td>\n",
              "      <td>0.796928</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Homais</td>\n",
              "      <td>104</td>\n",
              "      <td>0.988069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Rodolphe</td>\n",
              "      <td>96</td>\n",
              "      <td>0.790957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Madame</td>\n",
              "      <td>48</td>\n",
              "      <td>0.813232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Lheureux</td>\n",
              "      <td>42</td>\n",
              "      <td>0.991086</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>M. Homais</td>\n",
              "      <td>40</td>\n",
              "      <td>0.922977</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Justin</td>\n",
              "      <td>36</td>\n",
              "      <td>0.910620</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Binet</td>\n",
              "      <td>28</td>\n",
              "      <td>0.995274</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Félicité</td>\n",
              "      <td>26</td>\n",
              "      <td>0.775054</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Hippolyte</td>\n",
              "      <td>24</td>\n",
              "      <td>0.857947</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>M. Lheureux</td>\n",
              "      <td>24</td>\n",
              "      <td>0.955307</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>madame Homais</td>\n",
              "      <td>22</td>\n",
              "      <td>0.890803</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Monsieur</td>\n",
              "      <td>21</td>\n",
              "      <td>0.830093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Rouault</td>\n",
              "      <td>16</td>\n",
              "      <td>0.969070</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Berthe</td>\n",
              "      <td>15</td>\n",
              "      <td>0.778214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Hivert</td>\n",
              "      <td>15</td>\n",
              "      <td>0.986507</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>madame Lefrançois</td>\n",
              "      <td>15</td>\n",
              "      <td>0.938374</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>père Rouault</td>\n",
              "      <td>15</td>\n",
              "      <td>0.890304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Canivet</td>\n",
              "      <td>14</td>\n",
              "      <td>0.983610</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Lefrançois</td>\n",
              "      <td>14</td>\n",
              "      <td>0.986711</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Tuvache</td>\n",
              "      <td>13</td>\n",
              "      <td>0.974829</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Bournisien</td>\n",
              "      <td>11</td>\n",
              "      <td>0.973066</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Lestiboudois</td>\n",
              "      <td>11</td>\n",
              "      <td>0.887517</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Rodol</td>\n",
              "      <td>11</td>\n",
              "      <td>0.551710</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>Vinçart</td>\n",
              "      <td>11</td>\n",
              "      <td>0.981382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>or</td>\n",
              "      <td>11</td>\n",
              "      <td>0.762558</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Conseiller</td>\n",
              "      <td>10</td>\n",
              "      <td>0.792756</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>L</td>\n",
              "      <td>10</td>\n",
              "      <td>0.847892</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-df5461ee-4420-4088-8653-a83a9bc6cd8a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-df5461ee-4420-4088-8653-a83a9bc6cd8a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-df5461ee-4420-4088-8653-a83a9bc6cd8a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-c8d3eb36-31a6-43b3-aa24-e9c7688c46b9\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c8d3eb36-31a6-43b3-aa24-e9c7688c46b9')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-c8d3eb36-31a6-43b3-aa24-e9c7688c46b9 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"    pass\",\n  \"rows\": 30,\n  \"fields\": [\n    {\n      \"column\": \"name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 30,\n        \"samples\": [\n          \"or\",\n          \"Rouault\",\n          \"Bournisien\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 63,\n        \"min\": 10,\n        \"max\": 300,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          300,\n          13,\n          15\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mean_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10578122954395552,\n        \"min\": 0.5517104322260077,\n        \"max\": 0.9952741542032787,\n        \"num_unique_values\": 30,\n        \"samples\": [\n          0.7625578723170541,\n          0.9690704457461834,\n          0.9730661403049122\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    }
  ]
}